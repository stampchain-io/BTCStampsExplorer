name: Newman Comprehensive Tests (Production Validation + Local Dev)

# This workflow includes:
# 1. Production validation (scheduled) - validates live stampchain.io endpoints
# 2. Local dev testing (push/PR) - runs Newman tests against local dev server with MySQL+Redis

on:
  push:
    branches: [main, dev]
    paths:
      - 'tests/postman/collections/comprehensive.json'
      - 'tests/postman/collections/pagination-validation.json'
      - 'tests/postman/collections/schema-contract-tests.json'
      - 'tests/postman/environments/comprehensive.json'
      - 'tests/postman/data/pagination-tests.json'
      - 'scripts/run-newman-comprehensive.sh'
      - 'scripts/run-newman-pagination-validation.sh'
      - 'scripts/analyze-newman-regression.js'
      - 'scripts/test-schema.sql'
      - 'scripts/test-seed-data.sql'
      - 'server/**'
      - 'routes/**'
      - 'lib/**'
      - '.github/workflows/newman-comprehensive-tests.yml'
  pull_request:
    branches: [main, dev]
    paths:
      - 'tests/postman/collections/comprehensive.json'
      - 'tests/postman/collections/pagination-validation.json'
      - 'tests/postman/collections/schema-contract-tests.json'
      - 'tests/postman/environments/comprehensive.json'
      - 'tests/postman/data/pagination-tests.json'
      - 'scripts/run-newman-comprehensive.sh'
      - 'scripts/run-newman-pagination-validation.sh'
      - 'scripts/analyze-newman-regression.js'
      - 'scripts/test-schema.sql'
      - 'scripts/test-seed-data.sql'
      - 'server/**'
      - 'routes/**'
      - 'lib/**'
      - '.github/workflows/newman-comprehensive-tests.yml'
  workflow_dispatch:
    inputs:
      test_folder:
        description: 'Specific test folder to run (e.g., "Stamps Endpoints")'
        required: false
        default: ''
      iterations:
        description: 'Number of iterations'
        required: false
        default: '1'
      verbose:
        description: 'Enable verbose output'
        required: false
        default: 'false'
  schedule:
    # Run daily at 2 AM UTC to validate production endpoints
    - cron: '0 2 * * *'

jobs:
  newman-comprehensive:
    name: Newman Integration Tests (Database Required)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    permissions:
      contents: read
      pull-requests: write
      issues: write
      
    env:
      CI: true
      NODE_ENV: test
      # Mock API keys for testing
      QUICKNODE_API_KEY: test-quicknode-key
      ANTHROPIC_API_KEY: test-anthropic-key
      PERPLEXITY_API_KEY: test-perplexity-key

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'

      - name: Cache npm dependencies
        uses: actions/cache@v5
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-newman-${{ hashFiles('**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-newman-
            ${{ runner.os }}-npm-

      - name: Verify test files exist
        run: |
          echo "Verifying test collection and environment files..."
          if [ ! -f "tests/postman/collections/comprehensive.json" ]; then
            echo "‚ùå Error: tests/postman/collections/comprehensive.json not found"
            echo "This file contains the comprehensive test collection (100+ tests)"
            exit 1
          fi
          
          if [ ! -f "tests/postman/environments/comprehensive.json" ]; then
            echo "‚ùå Error: tests/postman/environments/comprehensive.json not found"
            echo "Creating default environment file..."
            mkdir -p tests/postman/environments
            echo '{
              "id": "comprehensive-env",
              "name": "Comprehensive Test Environment",
              "values": [
                {"key": "dev_base_url", "value": "http://localhost:8000", "enabled": true},
                {"key": "prod_base_url", "value": "https://stampchain.io", "enabled": true}
              ]
            }' > tests/postman/environments/comprehensive.json
          fi
          
          echo "‚úÖ Test files found"
          echo "Collection size: $(wc -l < tests/postman/collections/comprehensive.json) lines"

      - name: Setup Docker Compose
        run: |
          echo "Docker version:"
          docker --version
          echo "Docker Compose version:"
          docker compose version
          
          # Ensure reports directory exists
          mkdir -p reports/newman-comprehensive
          chmod -R 755 reports

      - name: Configure test parameters
        id: test-config
        run: |
          # Set test parameters based on workflow inputs or defaults
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "NEWMAN_FOLDER=${{ github.event.inputs.test_folder }}" >> $GITHUB_ENV
            echo "NEWMAN_ITERATIONS=${{ github.event.inputs.iterations }}" >> $GITHUB_ENV
            echo "NEWMAN_VERBOSE=${{ github.event.inputs.verbose }}" >> $GITHUB_ENV
          else
            echo "NEWMAN_ITERATIONS=1" >> $GITHUB_ENV
            echo "NEWMAN_VERBOSE=false" >> $GITHUB_ENV
          fi
          
          # Always set production URL
          echo "PROD_BASE_URL=https://stampchain.io" >> $GITHUB_ENV
          
          # CI Mode: Since we don't have a dev server running in CI,
          # we'll run production-only tests but still use the dual-endpoint collection
          # The collection will just hit production for both dev and prod URLs
          echo "DEV_BASE_URL=https://stampchain.io" >> $GITHUB_ENV
          echo "TEST_MODE=ci-production-only" >> $GITHUB_ENV
          
          # Note: For local development with dev server running, users should run:
          # DEV_BASE_URL=http://localhost:8000 PROD_BASE_URL=https://stampchain.io docker compose -f docker-compose.test.yml run --rm newman-comprehensive

      - name: Run Newman Comprehensive Tests
        id: newman-test
        run: |
          {
            echo "## Newman Integration Test Run"
            echo ""
            echo "‚ö†Ô∏è **Integration Test**: Tests live API endpoints with database access"
            echo ""
            echo "### Test Configuration"
            echo "- Collection: tests/postman/collections/comprehensive.json (100+ tests)"
            echo "- Coverage: 46/46 endpoints (100%)"
            echo "- Mode: ${{ env.TEST_MODE }}"
            echo "- DEV_BASE_URL: ${{ env.DEV_BASE_URL }}"
            echo "- PROD_BASE_URL: ${{ env.PROD_BASE_URL }}"
            echo "- Iterations: ${{ env.NEWMAN_ITERATIONS }}"
            
            if [ -n "${{ env.NEWMAN_FOLDER }}" ]; then
              echo "- Folder: ${{ env.NEWMAN_FOLDER }}"
            fi
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"
          
          # Run the tests
          docker compose -f docker-compose.test.yml run --rm newman-comprehensive || TEST_EXIT_CODE=$?
          
          # Check for test results
          if [ -d "reports/newman-comprehensive" ]; then
            {
              echo "### Test Results"
              echo "Reports generated in: reports/newman-comprehensive/"
              ls -la reports/newman-comprehensive/
            } >> "$GITHUB_STEP_SUMMARY"
          fi
          
          exit ${TEST_EXIT_CODE:-0}
        continue-on-error: true

      - name: Fix Docker file permissions
        if: always()
        run: |
          # Docker containers run as root and change file ownership
          # This prevents EACCES errors in subsequent steps
          sudo chown -R $(id -u):$(id -g) . || true

      - name: Analyze Regression Results
        id: regression-analysis
        if: always()
        run: |
          echo "Running regression analysis..."

          # Run the analysis (uses only Node.js built-in modules, no npm install needed)
          node scripts/analyze-newman-regression.js || ANALYSIS_EXIT_CODE=$?

          # Check if analysis report was created
          if ls reports/newman-comprehensive/*-analysis.json 1>/dev/null 2>&1; then
            echo "‚úÖ Regression analysis completed"

            # Extract summary for GitHub
            LATEST_ANALYSIS=$(ls -t reports/newman-comprehensive/*-analysis.json | head -1)
            if [ -f "$LATEST_ANALYSIS" ]; then
              {
                echo ""
                echo "### Regression Analysis Summary"
                echo ""

                # Parse JSON and add to summary
                node -e "
                  const fs = require('fs');
                  const analysis = JSON.parse(fs.readFileSync('$LATEST_ANALYSIS', 'utf8'));
                  console.log('- Breaking Changes: ' + analysis.summary.breaking);
                  console.log('- Non-Breaking Changes: ' + analysis.summary.nonBreaking);
                  console.log('- Performance Issues: ' + analysis.summary.performanceIssues);
                  console.log('- Performance Improvements: ' + analysis.summary.performanceImprovements);
                "
              } >> "$GITHUB_STEP_SUMMARY"
            fi
          else
            echo "‚ö†Ô∏è No analysis reports found ‚Äî Newman may not have generated output files"
          fi

          exit ${ANALYSIS_EXIT_CODE:-0}
        continue-on-error: true

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: newman-comprehensive-reports-${{ github.run_number }}
          path: reports/newman-comprehensive/
          retention-days: 30

      - name: Create PR comment with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            let comment = '## üß™ Newman Integration Test Results (API)\n\n';
            comment += '‚ö†Ô∏è **Integration Test**: These tests hit live API endpoints and require database access.\n\n';
            
            // Test execution status
            const testStatus = '${{ steps.newman-test.outcome }}';
            const analysisStatus = '${{ steps.regression-analysis.outcome }}';
            
            if (testStatus === 'success') {
              comment += '### ‚úÖ All API Tests Passed\n\n';
              comment += '- **Coverage**: 46/46 endpoints (100%)\n';
              comment += '- **Total Tests**: 92+\n';
            } else if (testStatus === 'failure') {
              comment += '### ‚ùå API Tests Failed\n\n';
              comment += 'Some tests did not pass. Please check the detailed report.\n\n';
            }
            
            // Regression analysis results
            if (analysisStatus === 'success' || analysisStatus === 'failure') {
              comment += '\n### üìä Regression Analysis\n\n';
              
              try {
                // Find the latest analysis file
                const analysisFiles = fs.readdirSync('reports/newman-comprehensive/')
                  .filter(f => f.endsWith('-analysis.json'))
                  .sort((a, b) => b.localeCompare(a));
                
                if (analysisFiles.length > 0) {
                  const latestAnalysis = JSON.parse(
                    fs.readFileSync(`reports/newman-comprehensive/${analysisFiles[0]}`, 'utf8')
                  );
                  
                  const summary = latestAnalysis.summary;
                  
                  if (summary.breaking > 0) {
                    comment += `‚ö†Ô∏è **Breaking Changes Detected**: ${summary.breaking}\n\n`;
                    
                    // List breaking changes
                    if (latestAnalysis.regressions.breaking.length > 0) {
                      comment += '<details><summary>Breaking Changes Details</summary>\n\n';
                      latestAnalysis.regressions.breaking.slice(0, 5).forEach(bc => {
                        comment += `- **${bc.request}**: ${bc.assertion}\n`;
                        comment += `  - Error: ${bc.error}\n`;
                      });
                      if (latestAnalysis.regressions.breaking.length > 5) {
                        comment += `\n... and ${latestAnalysis.regressions.breaking.length - 5} more\n`;
                      }
                      comment += '\n</details>\n\n';
                    }
                  } else {
                    comment += '‚úÖ **No Breaking Changes**\n\n';
                  }
                  
                  // Non-breaking changes
                  if (summary.nonBreaking > 0) {
                    comment += `‚ÑπÔ∏è **Non-Breaking Changes**: ${summary.nonBreaking}\n`;
                    comment += 'These are typically new optional fields or formatting changes.\n\n';
                  }
                  
                  // Performance
                  if (summary.performanceIssues > 0) {
                    comment += `‚ö° **Performance Issues**: ${summary.performanceIssues}\n`;
                  }
                  if (summary.performanceImprovements > 0) {
                    comment += `üöÄ **Performance Improvements**: ${summary.performanceImprovements}\n`;
                  }
                }
              } catch (e) {
                comment += 'Could not parse regression analysis results.\n';
                console.error('Error parsing analysis:', e);
              }
            }
            
            // Add links
            comment += '\n### üìé Resources\n\n';
            comment += '- [Test Reports Artifact](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})\n';
            comment += '- [Newman Testing Documentation](docs/NEWMAN_COMPREHENSIVE_TESTING.md)\n';
            comment += '- [API Endpoint Coverage](docs/API_ENDPOINT_AUDIT.md)\n';
            
            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('Newman Integration Test Results')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

      - name: Create regression issue (scheduled runs only)
        if: github.event_name == 'schedule' && steps.newman-test.outcome == 'failure'
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const today = new Date().toISOString().split('T')[0];

            // Check for existing open regression issue to avoid duplicates
            const { data: existingIssues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: 'api-regression',
              state: 'open',
            });

            if (existingIssues.length > 0) {
              // Add comment to existing issue instead of creating a new one
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssues[0].number,
                body: `### Regression still present (${today})\n\nScheduled Newman tests failed again.\n\n**Run**: ${runUrl}\n**Artifacts**: Check the run for detailed reports.`,
              });
              console.log(`Updated existing regression issue #${existingIssues[0].number}`);
              return;
            }

            // Build issue body with analysis details if available
            let analysisDetails = '';
            try {
              const analysisFiles = fs.readdirSync('reports/newman-comprehensive/')
                .filter(f => f.endsWith('-analysis.json'))
                .sort((a, b) => b.localeCompare(a));

              if (analysisFiles.length > 0) {
                const analysis = JSON.parse(
                  fs.readFileSync(`reports/newman-comprehensive/${analysisFiles[0]}`, 'utf8')
                );
                const summary = analysis.summary;
                analysisDetails = `\n### Regression Analysis\n- Breaking Changes: ${summary.breaking}\n- Non-Breaking Changes: ${summary.nonBreaking}\n- Performance Issues: ${summary.performanceIssues}\n`;

                if (analysis.regressions?.breaking?.length > 0) {
                  analysisDetails += '\n### Breaking Changes\n';
                  analysis.regressions.breaking.slice(0, 10).forEach(bc => {
                    analysisDetails += `- **${bc.request}**: ${bc.assertion}\n  - Error: \`${bc.error}\`\n`;
                  });
                  if (analysis.regressions.breaking.length > 10) {
                    analysisDetails += `\n... and ${analysis.regressions.breaking.length - 10} more\n`;
                  }
                }
              }
            } catch (e) {
              console.log('Could not parse analysis report:', e.message);
            }

            // Create new regression issue
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `API Regression Detected - ${today}`,
              body: `## Scheduled Newman Test Failure\n\nThe daily scheduled Newman API tests detected failures against production (stampchain.io).\n\n**Run**: ${runUrl}\n**Date**: ${today}\n**Trigger**: Scheduled (daily 2 AM UTC)\n${analysisDetails}\n### Next Steps\n1. Check the [workflow run](${runUrl}) for detailed test results\n2. Download the Newman report artifact for full failure details\n3. Investigate and fix the regression\n4. Close this issue when resolved\n\n---\n*Auto-created by scheduled API regression monitoring*`,
              labels: ['api-regression', 'bug', 'automated'],
            });

      - name: Summarize results
        if: always()
        run: |
          echo "=== Newman Comprehensive Test Summary ==="

          # Report Newman test status
          if [ "${{ steps.newman-test.outcome }}" == "failure" ]; then
            echo "‚ö†Ô∏è Newman tests had assertion failures (check step summary for details)"
            echo "   Note: /api/internal/* endpoints return 403 by design in CI"
          else
            echo "‚úÖ Newman tests passed"
          fi

          # Report regression analysis status
          if [ "${{ steps.regression-analysis.outcome }}" == "failure" ]; then
            echo "‚ö†Ô∏è Regression analysis flagged issues (check artifacts for report)"
          else
            echo "‚úÖ Regression analysis completed"
          fi

          echo "‚úÖ Monitoring run complete"

      - name: Fail on scheduled regression
        if: github.event_name == 'schedule' && steps.newman-test.outcome == 'failure'
        run: |
          echo "‚ùå Scheduled production validation detected API regressions"
          echo "   A GitHub issue has been created with details."
          exit 1

  pagination-validation:
    name: Pagination & Data Validation Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' || github.event_name == 'push'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'

      - name: Install Newman
        run: |
          npm install -g newman newman-reporter-html newman-reporter-json

      - name: Run Pagination Validation Tests
        id: pagination-test
        run: |
          echo "## Pagination Validation Test Run" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- Collection: tests/postman/collections/pagination-validation.json" >> $GITHUB_STEP_SUMMARY
          echo "- Test Data: postman-data-pagination-tests.json" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Run pagination validation tests
          ./scripts/run-newman-pagination-validation.sh || PAGINATION_EXIT_CODE=$?
          
          exit ${PAGINATION_EXIT_CODE:-0}
        continue-on-error: true

      - name: Upload pagination test reports
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: pagination-validation-reports-${{ github.run_number }}
          path: reports/newman-pagination-validation/
          retention-days: 30

  performance-benchmark:
    name: API Performance Benchmarking
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Run performance benchmarks
        id: perf-test
        run: |
          echo "## Performance Benchmarking" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- Iterations: 3" >> $GITHUB_STEP_SUMMARY
          echo "- Delay between requests: 100ms" >> $GITHUB_STEP_SUMMARY
          echo "- Focus: Stamps Endpoints folder" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Run performance-focused tests against production
          # (no dev server in CI, point both URLs at production)
          DEV_BASE_URL=https://stampchain.io \
          PROD_BASE_URL=https://stampchain.io \
          NEWMAN_ITERATIONS=3 \
          NEWMAN_DELAY_REQUEST=100 \
          NEWMAN_FOLDER="Stamps Endpoints" \
          docker compose -f docker-compose.test.yml run --rm newman-comprehensive
        continue-on-error: true

      - name: Fix Docker file permissions
        if: always()
        run: sudo chown -R $(id -u):$(id -g) . || true

      - name: Store performance results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: performance-benchmark-${{ github.run_number }}
          path: reports/newman-comprehensive/
          retention-days: 90

      - name: Summarize benchmark results
        if: always()
        run: |
          echo "=== Performance Benchmark Summary ==="
          if [ "${{ steps.perf-test.outcome }}" == "failure" ]; then
            echo "‚ö†Ô∏è Some benchmark assertions failed (check artifacts for details)"
            echo "   Note: /api/internal/* endpoints return 403 by design in CI"
          else
            echo "‚úÖ Performance benchmarks passed"
          fi
          echo "‚úÖ Benchmark run complete"

  newman-local-dev:
    name: Newman Tests - Local Dev Server
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: github.event_name == 'push' || github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch'

    permissions:
      contents: read
      pull-requests: write
      issues: write

    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: test
          MYSQL_DATABASE: btcstamps_test
        ports:
          - 3306:3306
        options: >-
          --health-cmd="mysqladmin ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      CI: true
      DENO_ENV: development
      # Database configuration
      DB_HOST: 127.0.0.1
      DB_PORT: 3306
      DB_USER: root
      DB_PASSWORD: test
      DB_NAME: btcstamps_test
      # Redis configuration
      REDIS_URL: redis://127.0.0.1:6379
      ELASTICACHE_ENDPOINT: 127.0.0.1:6379
      SKIP_REDIS_CONNECTION: false
      # Mock API keys for testing
      QUICKNODE_API_KEY: test-quicknode-key
      ANTHROPIC_API_KEY: test-anthropic-key
      PERPLEXITY_API_KEY: test-perplexity-key
      # Mock external APIs for POST endpoint testing (Counterparty, mempool.space, Blockstream)
      XCP_API_URL: http://localhost:18443/v2
      MEMPOOL_API_URL: http://localhost:18443/mempool/api
      BLOCKSTREAM_API_URL: http://localhost:18443/blockstream/api

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup Deno
        uses: denoland/setup-deno@v2
        with:
          deno-version: v2.6.9

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'

      - name: Cache Deno dependencies
        uses: actions/cache@v5
        with:
          path: |
            ~/.deno
            ~/.cache/deno
          key: ${{ runner.os }}-deno-newman-${{ hashFiles('**/deno.json', '**/import_map.json') }}
          restore-keys: |
            ${{ runner.os }}-deno-newman-
            ${{ runner.os }}-deno-

      - name: Cache npm dependencies
        uses: actions/cache@v5
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-newman-${{ hashFiles('**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-newman-
            ${{ runner.os }}-npm-

      - name: Wait for MySQL
        run: |
          echo "Waiting for MySQL to be ready..."
          timeout 60 bash -c 'until mysqladmin ping -h 127.0.0.1 -P 3306 -u root -ptest --silent; do
            echo "MySQL not ready yet, waiting..."
            sleep 2
          done'
          echo "‚úÖ MySQL is ready"

      - name: Wait for Redis
        run: |
          echo "Waiting for Redis to be ready..."
          timeout 30 bash -c 'until nc -z 127.0.0.1 6379; do
            echo "Redis not ready yet, waiting..."
            sleep 1
          done'
          echo "‚úÖ Redis is ready"

      - name: Load test schema
        run: |
          echo "Loading test schema..."
          mysql -h 127.0.0.1 -P 3306 -u root -ptest btcstamps_test < scripts/test-schema.sql
          echo "‚úÖ Test schema loaded"

      - name: Load test seed data
        run: |
          echo "Loading test seed data..."
          mysql -h 127.0.0.1 -P 3306 -u root -ptest btcstamps_test < scripts/test-seed-data.sql
          echo "‚úÖ Test seed data loaded"

      - name: Verify test data
        run: |
          echo "Verifying test data..."
          mysql -h 127.0.0.1 -P 3306 -u root -ptest btcstamps_test -e "SHOW TABLES;"
          mysql -h 127.0.0.1 -P 3306 -u root -ptest btcstamps_test -e "SELECT COUNT(*) AS stamp_count FROM StampTableV4;"
          mysql -h 127.0.0.1 -P 3306 -u root -ptest btcstamps_test -e "SELECT COUNT(*) AS block_count FROM blocks;"
          echo "‚úÖ Test data verified"

      - name: Cache Deno dependencies for dev server
        run: |
          echo "Caching Deno dependencies..."
          deno cache --no-check main.ts dev.ts

      - name: Start mock external API server
        run: |
          echo "Starting mock external API server for POST endpoint testing..."
          nohup deno run --allow-net --allow-env scripts/mock-external-apis.ts > mock-api-server.log 2>&1 &
          echo $! > mock-api-server.pid
          echo "Mock server started with PID: $(cat mock-api-server.pid)"

          # Wait for mock server to be ready
          timeout 15 bash -c 'until curl -f -s http://localhost:18443/health > /dev/null 2>&1; do
            echo "Mock server not ready yet, waiting..."
            sleep 1
          done' || {
            echo "‚ùå Mock API server failed to start"
            cat mock-api-server.log || echo "No logs available"
            exit 1
          }
          echo "‚úÖ Mock external API server is ready"

      - name: Start dev server
        run: |
          echo "Starting Deno dev server in background..."
          # Start dev server without watch mode for CI
          # XCP_API_URL, MEMPOOL_API_URL, BLOCKSTREAM_API_URL from job env
          # point to mock server for POST endpoint testing
          DENO_ENV=development \
          DB_HOST=127.0.0.1 \
          DB_USER=root \
          DB_PASSWORD=test \
          DB_NAME=btcstamps_test \
          REDIS_URL=redis://127.0.0.1:6379 \
          XCP_API_URL=http://localhost:18443/v2 \
          MEMPOOL_API_URL=http://localhost:18443/mempool/api \
          BLOCKSTREAM_API_URL=http://localhost:18443/blockstream/api \
          nohup deno run -A dev.ts > dev-server.log 2>&1 &

          echo "Dev server started with PID: $!"
          echo $! > dev-server.pid

          echo "Waiting for dev server to be ready (max 60s)..."
          timeout 60 bash -c 'until curl -f -s http://localhost:8000/api/v2/health > /dev/null 2>&1; do
            echo "Dev server not ready yet, waiting..."
            sleep 2
          done' || {
            echo "‚ùå Dev server failed to start within 60 seconds"
            echo "=== Dev Server Logs ==="
            cat dev-server.log || echo "No logs available"
            exit 1
          }

          echo "‚úÖ Dev server is ready at http://localhost:8000"

      - name: Verify dev server health
        run: |
          echo "Checking dev server health endpoint..."
          curl -f http://localhost:8000/api/v2/health || {
            echo "‚ùå Health check failed"
            exit 1
          }
          echo "‚úÖ Health check passed"

      - name: Install Newman
        run: |
          echo "Installing Newman and reporters..."
          npm install -g newman newman-reporter-html newman-reporter-json

      - name: Verify test collection exists
        run: |
          echo "Verifying test collection and environment files..."
          if [ ! -f "tests/postman/collections/comprehensive.json" ]; then
            echo "‚ùå Error: tests/postman/collections/comprehensive.json not found"
            exit 1
          fi

          if [ ! -f "tests/postman/environments/comprehensive.json" ]; then
            echo "‚ö†Ô∏è Warning: tests/postman/environments/comprehensive.json not found"
            echo "Tests will run with dev_base_url as environment variable"
          fi

          echo "‚úÖ Test files verified"

      - name: Run Newman tests against localhost
        id: newman-local
        run: |
          echo "Running Newman tests against local dev server..."
          mkdir -p reports/newman-local-dev

          # Run Newman tests pointing to localhost with comprehensive seed data
          newman run tests/postman/collections/comprehensive.json \
            --env-var dev_base_url=http://localhost:8000 \
            --env-var prod_base_url=http://localhost:8000 \
            --env-var baseUrl=http://localhost:8000 \
            --env-var test_block=820000 \
            --env-var test_stamp_id=1384305 \
            --env-var test_cpid=A888354448084788958 \
            --env-var test_address=bc1qkqqre5xuqk60xtt93j297zgg7t6x0ul7gwjmv4 \
            --env-var test_tx_hash=e94be2793462692ca8fea3a54dd90ff4b18735196a2bc426382c11959533c8ca \
            --env-var test_src20_tx_hash=f353823cdc63ee24fe2167ca14d3bb9b6a54dd063b53382c0cd42f05d7262808 \
            --env-var test_src20_tick=stamp \
            --env-var test_cursed_id=-1832 \
            --env-var test_deploy_hash=77fb147b72a551cf1e2f0b37dccf9982a1c25623a7fe8b4d5efaac566cf63fed \
            --env-var test_tokenid=U0FUT1NISU5BS0FNT1RP \
            --env-var test_index=1942 \
            --env-var test_tick=stamp \
            --env-var test_timeout=10000 \
            --reporters cli,html,json \
            --reporter-html-export reports/newman-local-dev/newman-report.html \
            --reporter-json-export reports/newman-local-dev/newman-report.json \
            || NEWMAN_EXIT_CODE=$?

          echo "Newman tests completed"

          # Create summary
          {
            echo "## Newman Local Dev Test Results"
            echo ""
            echo "### Configuration"
            echo "- Base URL: http://localhost:8000"
            echo "- Collection: tests/postman/collections/comprehensive.json"
            echo "- Environment: Local dev server with MySQL + Redis"
            echo ""

            if [ -f "reports/newman-local-dev/newman-report.json" ]; then
              echo "### Results Summary"
              node -e "
                const fs = require('fs');
                const report = JSON.parse(fs.readFileSync('reports/newman-local-dev/newman-report.json', 'utf8'));
                const stats = report.run.stats;
                console.log('- Total Requests: ' + stats.requests.total);
                console.log('- Passed Assertions: ' + stats.assertions.passed);
                console.log('- Failed Assertions: ' + stats.assertions.failed);
                console.log('- Total Assertions: ' + stats.assertions.total);
                console.log('- Average Response Time: ' + Math.round(report.run.timings.responseAverage) + 'ms');
              "
            fi
          } >> "$GITHUB_STEP_SUMMARY"

          exit ${NEWMAN_EXIT_CODE:-0}
        continue-on-error: false

      - name: Run schema contract tests against localhost
        id: schema-contract-local
        run: |
          echo "Running schema contract tests against local dev server..."

          newman run tests/postman/collections/schema-contract-tests.json \
            --env-var base_url=http://localhost:8000 \
            --env-var test_block=820000 \
            --env-var test_stamp_id=1384305 \
            --env-var test_address=bc1qkqqre5xuqk60xtt93j297zgg7t6x0ul7gwjmv4 \
            --env-var test_tx_hash=f353823cdc63ee24fe2167ca14d3bb9b6a54dd063b53382c0cd42f05d7262808 \
            --env-var test_src20_tick=stamp \
            --env-var test_collection_id=2531AF5D3A023148764800FAA6CC883F \
            --env-var test_deploy_hash=77fb147b72a551cf1e2f0b37dccf9982a1c25623a7fe8b4d5efaac566cf63fed \
            --reporters cli,json \
            --reporter-json-export reports/newman-local-dev/schema-contract-report.json \
            || SCHEMA_EXIT_CODE=$?

          # Add schema contract results to summary
          {
            echo ""
            echo "## Schema Contract Test Results (Local Dev)"
            echo ""
            echo "- Collection: schema-contract-tests.json (20 endpoints)"
            echo "- Target: Local dev server (http://localhost:8000)"
            echo ""

            if [ -f "reports/newman-local-dev/schema-contract-report.json" ]; then
              node -e "
                const fs = require('fs');
                const report = JSON.parse(fs.readFileSync('reports/newman-local-dev/schema-contract-report.json', 'utf8'));
                const stats = report.run.stats;
                console.log('- Total Requests: ' + stats.requests.total);
                console.log('- Passed Assertions: ' + stats.assertions.passed);
                console.log('- Failed Assertions: ' + stats.assertions.failed);
                console.log('- Total Assertions: ' + stats.assertions.total);
              "
            fi
          } >> "$GITHUB_STEP_SUMMARY"

          exit ${SCHEMA_EXIT_CODE:-0}
        continue-on-error: false

      - name: Capture dev server logs on failure
        if: failure()
        run: |
          echo "=== Dev Server Logs ==="
          cat dev-server.log || echo "No logs available"

      - name: Stop dev server and mock API server
        if: always()
        run: |
          if [ -f dev-server.pid ]; then
            echo "Stopping dev server..."
            kill $(cat dev-server.pid) || true
            rm dev-server.pid
          fi
          if [ -f mock-api-server.pid ]; then
            echo "Stopping mock API server..."
            kill $(cat mock-api-server.pid) || true
            rm mock-api-server.pid
          fi

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: newman-local-dev-reports-${{ github.run_number }}
          path: reports/newman-local-dev/
          retention-days: 30

      - name: Upload dev server logs
        if: failure()
        uses: actions/upload-artifact@v6
        with:
          name: dev-server-logs-${{ github.run_number }}
          path: dev-server.log
          retention-days: 7

      - name: Create PR comment with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v8
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            let comment = '## üß™ Newman Local Dev Test Results\n\n';
            comment += '‚úÖ **Local Dev Server**: Tests run against localhost:8000 with MySQL + Redis\n\n';

            const testStatus = '${{ steps.newman-local.outcome }}';

            if (testStatus === 'success') {
              comment += '### ‚úÖ All Local Dev Tests Passed\n\n';

              try {
                const report = JSON.parse(fs.readFileSync('reports/newman-local-dev/newman-report.json', 'utf8'));
                const stats = report.run.stats;

                comment += `- **Total Requests**: ${stats.requests.total}\n`;
                comment += `- **Passed Assertions**: ${stats.assertions.passed}\n`;
                comment += `- **Failed Assertions**: ${stats.assertions.failed}\n`;
                comment += `- **Total Assertions**: ${stats.assertions.total}\n`;
                comment += `- **Average Response Time**: ${Math.round(report.run.timings.responseAverage)}ms\n`;
              } catch (e) {
                comment += 'Could not parse test results.\n';
              }
            } else {
              comment += '### ‚ùå Local Dev Tests Failed\n\n';
              comment += 'Some tests did not pass against the local dev server. Please check the detailed report.\n\n';
            }

            comment += '\n### üìé Resources\n\n';
            comment += '- [Test Reports Artifact](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})\n';

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Newman Local Dev Test Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

      - name: Summarize results
        if: always()
        run: |
          echo "=== Newman Local Dev Test Summary ==="

          if [ "${{ steps.newman-local.outcome }}" == "success" ]; then
            echo "‚úÖ Comprehensive Newman tests passed against local dev server"
          else
            echo "‚ùå Comprehensive Newman tests failed against local dev server"
          fi

          if [ "${{ steps.schema-contract-local.outcome }}" == "success" ]; then
            echo "‚úÖ Schema contract tests passed against local dev server"
          else
            echo "‚ùå Schema contract tests failed against local dev server"
          fi

          echo "‚úÖ Local dev test run complete"

  schema-contract-tests:
    name: Schema Contract Tests - Production Monitor
    runs-on: ubuntu-latest
    timeout-minutes: 10
    # Production monitoring only ‚Äî schema contracts are validated against local dev
    # in the newman-local-dev job. This job monitors production for regressions.
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'

    permissions:
      contents: read
      pull-requests: write
      issues: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '20'

      - name: Verify schema contract test collection exists
        run: |
          echo "Verifying schema-contract-tests.json exists..."
          if [ ! -f "tests/postman/collections/schema-contract-tests.json" ]; then
            echo "‚ùå Error: schema-contract-tests.json not found"
            exit 1
          fi
          echo "‚úÖ Schema contract test collection found"

      - name: Run schema contract tests against production
        id: schema-contract-test
        run: |
          echo "## Schema Contract Tests" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- Collection: schema-contract-tests.json" >> $GITHUB_STEP_SUMMARY
          echo "- Endpoints: 20 high-traffic GET endpoints" >> $GITHUB_STEP_SUMMARY
          echo "- Target: Production (https://stampchain.io)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Run schema contract tests against production
          DEV_BASE_URL=https://stampchain.io \
          PROD_BASE_URL=https://stampchain.io \
          NEWMAN_COLLECTION=tests/postman/collections/schema-contract-tests.json \
          NEWMAN_REPORTERS=cli,json \
          docker compose -f docker-compose.test.yml run --rm newman
        continue-on-error: true  # Production monitoring ‚Äî non-blocking

      - name: Fix Docker file permissions
        if: always()
        run: sudo chown -R $(id -u):$(id -g) . || true

      - name: Parse test results
        if: always()
        id: parse-results
        run: |
          echo "Parsing Newman JSON results..."

          # Find the most recent newman JSON report
          LATEST_REPORT=$(find reports/newman -name "*.json" -type f -printf '%T+ %p\n' | sort -r | head -n 1 | cut -d' ' -f2-)

          if [ -z "$LATEST_REPORT" ]; then
            echo "‚ö†Ô∏è No JSON report found"
            echo "total_tests=0" >> $GITHUB_OUTPUT
            echo "passed_tests=0" >> $GITHUB_OUTPUT
            echo "failed_tests=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Found report: $LATEST_REPORT"

          # Extract test counts using jq
          TOTAL=$(jq -r '.run.stats.tests.total // 0' "$LATEST_REPORT")
          PASSED=$(jq -r '.run.stats.tests.passed // 0' "$LATEST_REPORT")
          FAILED=$(jq -r '.run.stats.tests.failed // 0' "$LATEST_REPORT")

          echo "total_tests=$TOTAL" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED" >> $GITHUB_OUTPUT

          echo "Total tests: $TOTAL"
          echo "Passed: $PASSED"
          echo "Failed: $FAILED"

      - name: Upload test results artifact
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: schema-contract-test-results-${{ github.run_number }}
          path: reports/newman/
          retention-days: 30

      - name: Comment on PR with results
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v8
        with:
          script: |
            const total = '${{ steps.parse-results.outputs.total_tests }}';
            const passed = '${{ steps.parse-results.outputs.passed_tests }}';
            const failed = '${{ steps.parse-results.outputs.failed_tests }}';

            const status = failed === '0' ? '‚úÖ' : '‚ùå';
            const comment = `## ${status} Schema Contract Test Results

            **Collection:** schema-contract-tests.json
            **Endpoints Tested:** 20 high-traffic GET endpoints
            **Target:** Production (https://stampchain.io)

            ### Results
            - **Total Tests:** ${total}
            - **Passed:** ${passed}
            - **Failed:** ${failed}

            ${failed !== '0' ? '‚ö†Ô∏è **Breaking schema changes detected!** Review failing tests before merging.' : '‚úÖ All schema contract tests passed - no breaking changes detected.'}

            <details>
            <summary>Endpoints Covered</summary>

            1. GET /api/v2/stamps - Paginated stamps list
            2. GET /api/v2/stamps/{id} - Single stamp detail
            3. GET /api/v2/stamps/balance/{address} - Stamp balances
            4. GET /api/v2/stamps/block/{block_index} - Stamps by block
            5. GET /api/v2/stamps/search - Stamp search
            6. GET /api/v2/stamps/ident/{ident} - Stamps by ident
            7. GET /api/v2/src20 - Paginated SRC-20 transactions
            8. GET /api/v2/src20/balance/{address} - SRC-20 balances
            9. GET /api/v2/src20/balance/{address}/{tick} - Single SRC-20 balance
            10. GET /api/v2/src20/tick/{tick} - Tick data
            11. GET /api/v2/src20/tick/{tick}/deploy - Tick deployment info
            12. GET /api/v2/src20/tx/{tx_hash} - SRC-20 transaction detail
            13. GET /api/v2/src20/block/{block_index} - SRC-20 by block
            14. GET /api/v2/block/{block_index} - Block info
            15. GET /api/v2/balance/{address} - Combined balance
            16. GET /api/v2/collections - Collections list
            17. GET /api/v2/collections/{id} - Collection detail
            18. GET /api/v2/src101 - SRC-101 tokens
            19. GET /api/v2/src101/balance/{address} - SRC-101 balances
            20. GET /api/v2/src101/tx - SRC-101 transactions
            </details>

            [View detailed results artifact](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            `;

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Schema Contract Test Results')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

      - name: Summarize results
        if: always()
        run: |
          echo "=== Schema Contract Test Summary ==="

          TOTAL="${{ steps.parse-results.outputs.total_tests }}"
          PASSED="${{ steps.parse-results.outputs.passed_tests }}"
          FAILED="${{ steps.parse-results.outputs.failed_tests }}"

          echo "Total tests: $TOTAL"
          echo "Passed: $PASSED"
          echo "Failed: $FAILED"

          if [ "$FAILED" == "0" ] && [ "$TOTAL" != "0" ]; then
            echo "‚úÖ All schema contract tests passed"
          elif [ "$TOTAL" == "0" ]; then
            echo "‚ö†Ô∏è No test results found"
          else
            echo "‚ùå $FAILED schema contract tests failed"
          fi

          echo "‚úÖ Schema contract test run complete"